{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module INM378/IN3031: Digital Signal Processing and Audio Programming\n",
    "## Lab 4 - Fourier Transform in Practice, Convolution, Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setup dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    import subprocess\n",
    "    import os.path\n",
    "    p = subprocess.run(['git', 'rev-parse', '--is-inside-work-tree'], stdout=subprocess.PIPE, universal_newlines=True)\n",
    "    if p.stdout == 'true\\n':\n",
    "        !git pull\n",
    "    else:\n",
    "        if not os.path.isdir('city_dsp_ap'):\n",
    "            !git clone --depth 1 -q https://github.com/jpauwels/city_dsp_ap.git\n",
    "        %cd city_dsp_ap\n",
    "except:\n",
    "    %cd city_dsp_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal, fft\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "from dsp_ap.operations import circ_convolve\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (13,6) # increase the default size of the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introducing **matplotlib** and **scipy.fft**\n",
    "\n",
    "Up to now, we've been relying on functionality in the **`dsp_ap`** library for all our plotting and frequency transformation needs. This library has been specifically created for these lab sessions, to hide some of the initial complexity, so you shouldn't count on it being present for your real-word applications. Therefore, we will **now start** to learn how to implement similar functionality ourselves, using **only libraries** that are commonly available in the [**scientific Python ecosystem**](https://scipy-lectures.org). Feel free to keep on using `dsp_ap` for quick prototyping and verification though.\n",
    "\n",
    "We will use the [`scipy.fft`](https://docs.scipy.org/doc/scipy/reference/fft.html) module to calculate frequency transformations, which is part of the larger [SciPy](https://scipy.org/) library. It has already been imported into our Python namespace as `fft`. We've been using the [`signal`](https://docs.scipy.org/doc/scipy/reference/signal.html) and [`io.wavfile`](https://docs.scipy.org/doc/scipy/reference/io.html#module-scipy.io.wavfile) modules of the same library before for creating and reading waveforms and will use it even more to create windows functions and perform filtering today and in later sessions.\n",
    "\n",
    "For plottting, we will use the [**Matplotlib**](https://matplotlib.org) library. There are plenty of good [tutorials](https://matplotlib.org/tutorials/index.html) available on its [documentation](https://matplotlib.org/contents.html) website, but we'll be introducing the necessary functions as we go along. The simplest way to get started is by using the `matplotlib.pyplot` interface, which is available in our namespace as `plt`.\n",
    "\n",
    "You will notice that the plots created with Matplotlib will have different aesthetics and functionality than the ones produced by `dsp_ap`. This is because the `dsp_ap` library is built on top of the [bokeh](https://bokeh.org/) visualisation toolkit. The latter has nice interactive functionality that make it very suitable for use in notebooks and education, but it requires a browser environment to run in. Therefore Matplotlib will be taught, as it is useable in more situations and is the industry standard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Spectrum of window function\n",
    "\n",
    "Create a **Hann window** using the [**`hann`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.windows.hann.html) function in `scipy.signal.windows` and calculate its Fourier transform by using the [`rfft`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.rfft.html) function in `scipy.fft`. Note that we are relying on the fact that the window is a real-valued signal, so we can call the real-valued FFT. This is slightly more efficient and gives a simpler, one-sided output. For Fourier transforms of different types of input, check the [documentation](https://docs.scipy.org/doc/scipy/reference/fft.html) of the `scipy.fft` module.\n",
    "\n",
    "Plot the **absolute** of the spectrum using [**`np.abs`**](https://docs.scipy.org/doc/numpy/reference/generated/numpy.absolute.html) and [**`plt.plot`**](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html). Remember that you can start a new figure with [`plt.figure`]() and add a title to your plot with [`plt.title`]().\n",
    "\n",
    "**Subtract** the **mean** from the window function and observe how the symmetry of the spectrum changes. Why is this the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Frequency-domain filtering\n",
    "\n",
    "Take the FFT (`fft.rfft`) of `audio/carrier.wav` and apply filtering in the frequency domain. That means you can apply a factor to a frequency band, amplify or delete it, or apply a sine function as an envelope over frequency.\n",
    "\n",
    "The easiest way to do this, is to manually create a **frequency response** of the same length as the spectrum and then apply it to the spectrum by **multiplying** the **spectrum** by the frequency response. So a frequency resonse of 1 for a certain bin will leave it unaltered, a value between 0 and 1 will reduce it and any values above 1 will amplify that frequency. You can generate sequences of zeros, ones or constant values with [`np.zeros`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html), [`np.ones`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html) and [`np.full`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.full.html), respectively. Then you can concatenate them with [`np.concatenate`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html) until you achieve a frequency response of the same length as the spectrum.\n",
    "\n",
    "Finally **apply** the **inverse FFT** (function [`irfft`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.irfft.html) in `scipy.fft`) and listen to the resynthesized sound. To play back sound, you can pass an array of samples and their samplerate to the [`Audio`](https://ipython.readthedocs.io/en/5.x/api/generated/IPython.display.html#IPython.display.Audio) class of `IPython.display` as follows: `display(Audio(<samples>, rate=<samplerate>))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Time-domain filtering\n",
    "\n",
    "Take the manually constructed **frequency response** you created in the previous section and transform it to the **time domain** using **`fft.irfft`** again. **Convolve** the result with the audio signal `audio/carrier.wav` and compare the result to that of the previous section. To get the **exact equivalent** of the spectral filtering, especially for short signals, you need to apply the ***circular*** convolution (function `circ_convolve(signal1, signal2)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Real-time filtering\n",
    "\n",
    "Explain why we **can apply** filtering by **convolution** in **real time**, as opposed to frequency domain filtering? (Ignore the circular version of convolution mentioned above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_answer here_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}